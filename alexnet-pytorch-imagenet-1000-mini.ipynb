{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torchvision.transforms import Resize, ToTensor, Compose\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\nfrom pathlib import Path\nimport random\nimport matplotlib.pyplot as plt\n\n# Configuration de l'appareil\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Définition des transformations\ntrain_transform = Compose([\n    Resize((224, 224)), \n    ToTensor()\n])\n\n# Création du Dataset et du DataLoader\ndata_dir = Path('/kaggle/input/imagenetmini-1000/imagenet-mini')\n\n# Dataset d'entraînement et de validation\ntraining_dataset = ImageFolder(root=data_dir / 'train', transform=train_transform)\n\n# Diviser les données en 80% entraînement et 20% validation\ntrain_size = int(0.8 * len(training_dataset))\nval_size = len(training_dataset) - train_size\ntrain_dataset, val_dataset = random_split(training_dataset, [train_size, val_size])\n\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\nval_dataloader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)","metadata":{"_uuid":"041804fc-adf1-4dda-af3a-514d1b4e28e8","_cell_guid":"8cd1aa46-e241-4675-afcd-6b6d2f09dee2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-22T14:07:02.696891Z","iopub.execute_input":"2024-10-22T14:07:02.697623Z","iopub.status.idle":"2024-10-22T14:07:04.970790Z","shell.execute_reply.started":"2024-10-22T14:07:02.697584Z","shell.execute_reply":"2024-10-22T14:07:04.969712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Définition du modèle AlexNet\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 96, kernel_size=11, stride=4),  # Conv1\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.LocalResponseNorm(5),\n            \n            nn.Conv2d(96, 256, kernel_size=5, padding=2),  # Conv2\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.LocalResponseNorm(5),\n            \n            nn.Conv2d(256, 384, kernel_size=3, padding=1),  # Conv3\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(384, 384, kernel_size=3, padding=1),  # Conv4\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(384, 256, kernel_size=3, padding=1),  # Conv5\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(self._get_flattened_size(), 4096),  # FC6\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),  # FC7\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes)  # FC8\n        )\n    def _get_flattened_size(self):\n        with torch.no_grad():\n            dummy_input = torch.randn(1, 3, 224, 224)  # Create a dummy input tensor\n            features_output = self.features(dummy_input)  # Pass through the features part\n            return features_output.view(1, -1).size(1)  # Get the flattened size\n            \n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)  # Aplatir toutes les dimensions sauf la première\n        x = self.classifier(x)\n        return x","metadata":{"_uuid":"143dc4da-f3f9-4841-9a54-cee52e64ccef","_cell_guid":"d149823f-7ffc-44f3-a9d8-94455d3d51ea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-22T14:18:04.052123Z","iopub.execute_input":"2024-10-22T14:18:04.052487Z","iopub.status.idle":"2024-10-22T14:18:04.064578Z","shell.execute_reply.started":"2024-10-22T14:18:04.052448Z","shell.execute_reply":"2024-10-22T14:18:04.063810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialisation du modèle, de la fonction de perte et de l'optimiseur\nalexnet_model = AlexNet(num_classes=len(training_dataset.classes)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(alexnet_model.parameters(), lr=0.001)\n\n# Vérification : le modèle est-il sur le GPU ?\nprint(\"Modèle sur l'appareil:\", next(alexnet_model.parameters()).device)\n\n# Fonction pour évaluer le modèle\ndef evaluate_model(dataloader):\n    alexnet_model.eval()  # Mettre le modèle en mode évaluation\n    total_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = alexnet_model(images)\n            loss = criterion(outputs, labels)\n\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    average_loss = total_loss / len(dataloader)\n    accuracy = correct / total\n    return average_loss, accuracy\n\n# Boucle d'entraînement avec validation\nnum_epochs = 10\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\nfor epoch in range(num_epochs):\n    alexnet_model.train()  # Mettre le modèle en mode entraînement\n    running_loss = 0.0\n\n    for images, labels in train_dataloader:\n        images, labels = images.to(device), labels.to(device)\n        \n        # Réinitialiser les gradients\n        optimizer.zero_grad()\n        \n        # Passage avant\n        outputs = alexnet_model(images)\n        \n        # Calcul de la perte\n        loss = criterion(outputs, labels)\n        \n        # Passage arrière et optimisation\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n\n    # Évaluation du modèle sur l'ensemble d'entraînement\n    train_loss, train_accuracy = evaluate_model(train_dataloader)\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n\n    # Évaluation du modèle sur l'ensemble de validation\n    val_loss, val_accuracy = evaluate_model(val_dataloader)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader):.4f}, '\n          f'Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n\n# Visualisation des pertes et des précisions\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Training Loss')\nplt.plot(val_losses, label='Validation Loss', linestyle='--')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Training Accuracy', color='orange')\nplt.plot(val_accuracies, label='Validation Accuracy', color='green', linestyle='--')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n","metadata":{"_uuid":"38d3875b-3efc-44eb-9968-dd98c3db1882","_cell_guid":"4b506a3a-8704-4ac9-9b8e-aec837d017af","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-22T14:18:07.871113Z","iopub.execute_input":"2024-10-22T14:18:07.871498Z","iopub.status.idle":"2024-10-22T14:45:41.803736Z","shell.execute_reply.started":"2024-10-22T14:18:07.871463Z","shell.execute_reply":"2024-10-22T14:45:41.802811Z"}},"outputs":[],"execution_count":null}]}